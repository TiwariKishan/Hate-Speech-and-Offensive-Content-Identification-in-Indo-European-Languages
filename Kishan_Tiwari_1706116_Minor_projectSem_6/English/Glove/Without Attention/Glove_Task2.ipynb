{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Attention Glove_Task2.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "_MwQbYAFwmMo",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 101
        },
        "outputId": "7a4878ae-f2d7-48e9-88ff-17590c12822c"
      },
      "source": [
        "%tensorflow_version 1.x   #Using tensorflow 1.x\n",
        "import tensorflow as tf\n",
        "device_name = tf.test.gpu_device_name()\n",
        "if device_name != '/device:GPU:0':      #use GPU for fast process\n",
        "  raise SystemError('GPU device not found')\n",
        "#print('Found GPU at: {}'.format(device_name))"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "`%tensorflow_version` only switches the major version: 1.x or 2.x.\n",
            "You set: `1.x   #Using tensorflow 1.x`. This will be interpreted as: `1.x`.\n",
            "\n",
            "\n",
            "TensorFlow 1.x selected.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FAV9fUzI6Sks",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "f8c012e1-7f6a-4ee2-ec31-f1ac4d5911c1"
      },
      "source": [
        "print(tf.__version__)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1.15.2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pJ6MP-TptKog",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "b21d0bc9-b2dd-46c0-8906-bb04122478d8"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O05nwxAVWv1Q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import requests  \n",
        "file_url = \"http://nlp.stanford.edu/data/glove.6B.zip\"          #Download glove here is the link\n",
        "    \n",
        "r = requests.get(file_url, stream = True)  \n",
        "  \n",
        "with open(\"glove.6B.zip\", \"wb\") as file:  \n",
        "    for block in r.iter_content(chunk_size = 1024): \n",
        "         if block:  \n",
        "             file.write(block) "
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q7as22nDWy05",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 151
        },
        "outputId": "f3f334f2-afcb-4962-e6f2-34cb108d1b8f"
      },
      "source": [
        "!apt install unzip"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "unzip is already the newest version (6.0-21ubuntu1).\n",
            "The following package was automatically installed and is no longer required:\n",
            "  libnvidia-common-440\n",
            "Use 'apt autoremove' to remove it.\n",
            "0 upgraded, 0 newly installed, 0 to remove and 59 not upgraded.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QhtZ4qcSXb8_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "e95cd23e-fd00-4bb3-b485-bb55c949c4d1"
      },
      "source": [
        "cd '/content/go'      #downloaded in server but not in my drive it is fast to access"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[Errno 2] No such file or directory: '/content/go #downloaded in server but not in my drive it is fast to access'\n",
            "/content\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ycvra3e0XNpq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 101
        },
        "outputId": "063aa4cf-67ee-4db1-e156-1a72c8866da1"
      },
      "source": [
        "!unzip  '/content/glove.6B.zip' -d go"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Archive:  /content/glove.6B.zip\n",
            "  inflating: go/glove.6B.50d.txt     \n",
            "  inflating: go/glove.6B.100d.txt    \n",
            "  inflating: go/glove.6B.200d.txt    \n",
            "  inflating: go/glove.6B.300d.txt    \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ykMyHL-keYKz",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "b7dc87cf-e239-4e3c-adbb-f04ea3bb4888"
      },
      "source": [
        "'''import numpy as np\n",
        "np.random.seed(42)\n",
        "import pandas as pd\n",
        "import re\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import f1_score\n",
        "import keras\n",
        "from keras.models import Model\n",
        "from keras.layers import Input, Embedding, Dense, Conv2D, MaxPool2D,GlobalAveragePooling1D\n",
        "from keras.layers import Dense, Input, CuDNNLSTM, Embedding, Dropout, Activation, CuDNNGRU, Conv1D\n",
        "from keras.layers import Bidirectional, GlobalMaxPool1D, GlobalMaxPooling1D, GlobalAveragePooling1D\n",
        "from keras.layers import Reshape, Flatten, Concatenate, Dropout, SpatialDropout1D\n",
        "from keras.preprocessing import text, sequence\n",
        "from keras.callbacks import Callback\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')'''\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import re\n",
        "import keras\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import f1_score\n",
        "from keras.models import Model\n",
        "from keras.layers import Input, Embedding, Dense, Conv2D, MaxPool2D\n",
        "from keras.layers import Reshape, Flatten, Concatenate, Dropout, SpatialDropout1D\n",
        "from keras.preprocessing import text, sequence\n",
        "from keras.callbacks import Callback\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MceJKUmGgWQI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "EMBEDDING_FILE = '/content/go/glove.6B.300d.txt'      \n",
        "train = pd.read_csv('/content/drive/My Drive/Hate Speech/english_dataset.tsv', sep = '\\t', encoding=\"latin-1\")\n",
        "test = pd.read_csv('/content/drive/My Drive/Hate Speech/hasoc2019_en_test-2919.tsv', sep = '\\t', encoding=\"latin-1\")"
      ],
      "execution_count": 206,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yOYez7m5w8BH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train=train[train.task_2!=\"NONE\"]       #drop none\n",
        "test=test[test.task_2!=\"NONE\"]\n",
        "train=train.reset_index(drop=True)    #reset index\n",
        "test=test.reset_index(drop=True)\n",
        "X_train = train[\"text\"]\n",
        "y_train = train[\"task_2\"]       #For task 2\n",
        "X_test = test[\"text\"]\n",
        "y_test = test[\"task_2\"]"
      ],
      "execution_count": 207,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bAGwPh34Nn4m",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        },
        "outputId": "c2c0561f-230d-449c-8e0e-bd8b8a2d164a"
      },
      "source": [
        "import nltk\n",
        "from nltk.corpus import stopwords \n",
        "from nltk.tokenize import word_tokenize \n",
        "nltk.download('stopwords')"
      ],
      "execution_count": 208,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 208
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0NWa1dOIE1bK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Remove stopwords from the text\n",
        "stop_words = set(stopwords.words('english')) \n",
        "ix=0\n",
        "for i in X_train:\n",
        "  word_tokens = (i[0].split())  \n",
        "  for w in word_tokens: \n",
        "    if w not in stop_words: \n",
        "        X_train[ix]=X_train[ix]+(w) \n",
        "  ix=ix+1\n",
        "ix=0\n",
        "for i in X_test:\n",
        "  word_tokens = (i[0].split())  \n",
        "  for w in word_tokens: \n",
        "    if w not in stop_words: \n",
        "        X_test[ix]= X_test[ix]+(w) \n",
        "  ix=ix+1"
      ],
      "execution_count": 209,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tYcf7mNm1gI0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#remove punctuations\n",
        "puncts = [',', '.', '\"', ':', ')', '(', '-', '!', '?', '|', ';', \"'\", '$', '&', '/', '[', ']', '>', '%', '=', '#', '*', '+', '\\\\', '•',  '~', '@', '£', \n",
        " '·', '_', '{', '}', '©', '^', '®', '`',  '<', '→', '°', '€', '™', '›',  '♥', '←', '×', '§', '″', '′', 'Â', '█', '½', 'à', '…', \n",
        " '“', '★', '”', '–', '●', 'â', '►', '−', '¢', '²', '¬', '░', '¶', '↑', '±', '¿', '▾', '═', '¦', '║', '―', '¥', '▓', '—', '‹', '─', \n",
        " '▒', '：', '¼', '⊕', '▼', '▪', '†', '■', '’', '▀', '¨', '▄', '♫', '☆', 'é', '¯', '♦', '¤', '▲', 'è', '¸', '¾', 'Ã', '⋅', '‘', '∞', \n",
        " '∙', '）', '↓', '、', '│', '（', '»', '，', '♪', '╩', '╚', '³', '・', '╦', '╣', '╔', '╗', '▬', '❤', 'ï', 'Ø', '¹', '≤', '‡', '√', ]\n",
        "\n",
        "def clean_text(x):\n",
        "    x = str(x)\n",
        "    for punct in puncts:\n",
        "        if punct in x:\n",
        "            x = x.replace(punct, '')\n",
        "    return x"
      ],
      "execution_count": 210,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nmGlWiP95MuA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "ix=0\n",
        "for i in X_train:\n",
        "  X_train[ix]=clean_text(i)\n",
        "  ix=ix+1\n",
        "ix=0\n",
        "for i in X_test:\n",
        "  X_test[ix]=clean_text(i)\n",
        "  ix=ix+1"
      ],
      "execution_count": 211,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wflYqloM5G4t",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#clean the numbers\n",
        "def clean_numbers(x):\n",
        "    if bool(re.search(r'\\d', x)):\n",
        "        x = re.sub('[0-9]{5,}', '#####', x)\n",
        "        x = re.sub('[0-9]{4}', '####', x)\n",
        "        x = re.sub('[0-9]{3}', '###', x)\n",
        "        x = re.sub('[0-9]{2}', '##', x)\n",
        "    return x"
      ],
      "execution_count": 212,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nWXG_29D1lvf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "ix=0\n",
        "for i in X_train:\n",
        "  X_train[ix]=clean_numbers(i)\n",
        "  ix=ix+1\n",
        "ix=0\n",
        "for i in X_test:\n",
        "  X_test[ix]=clean_numbers(i)\n",
        "  ix=ix+1"
      ],
      "execution_count": 213,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wtj562wk6T9n",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#remove contractions\n",
        "contraction_dict = {\"ain't\": \"is not\", \"aren't\": \"are not\",\"can't\": \"cannot\", \"'cause\": \"because\", \"could've\": \"could have\", \"couldn't\": \"could not\", \"didn't\": \"did not\",  \"doesn't\": \"does not\", \"don't\": \"do not\", \"hadn't\": \"had not\", \"hasn't\": \"has not\", \"haven't\": \"have not\", \"he'd\": \"he would\",\"he'll\": \"he will\", \"he's\": \"he is\", \"how'd\": \"how did\", \"how'd'y\": \"how do you\", \"how'll\": \"how will\", \"how's\": \"how is\",  \"I'd\": \"I would\", \"I'd've\": \"I would have\", \"I'll\": \"I will\", \"I'll've\": \"I will have\",\"I'm\": \"I am\", \"I've\": \"I have\", \"i'd\": \"i would\", \"i'd've\": \"i would have\", \"i'll\": \"i will\",  \"i'll've\": \"i will have\",\"i'm\": \"i am\", \"i've\": \"i have\", \"isn't\": \"is not\", \"it'd\": \"it would\", \"it'd've\": \"it would have\", \"it'll\": \"it will\", \"it'll've\": \"it will have\",\"it's\": \"it is\", \"let's\": \"let us\", \"ma'am\": \"madam\", \"mayn't\": \"may not\", \"might've\": \"might have\",\"mightn't\": \"might not\",\"mightn't've\": \"might not have\", \"must've\": \"must have\", \"mustn't\": \"must not\", \"mustn't've\": \"must not have\", \"needn't\": \"need not\", \"needn't've\": \"need not have\",\"o'clock\": \"of the clock\", \"oughtn't\": \"ought not\", \"oughtn't've\": \"ought not have\", \"shan't\": \"shall not\", \"sha'n't\": \"shall not\", \"shan't've\": \"shall not have\", \"she'd\": \"she would\", \"she'd've\": \"she would have\", \"she'll\": \"she will\", \"she'll've\": \"she will have\", \"she's\": \"she is\", \"should've\": \"should have\", \"shouldn't\": \"should not\", \"shouldn't've\": \"should not have\", \"so've\": \"so have\",\"so's\": \"so as\", \"this's\": \"this is\",\"that'd\": \"that would\", \"that'd've\": \"that would have\", \"that's\": \"that is\", \"there'd\": \"there would\", \"there'd've\": \"there would have\", \"there's\": \"there is\", \"here's\": \"here is\",\"they'd\": \"they would\", \"they'd've\": \"they would have\", \"they'll\": \"they will\", \"they'll've\": \"they will have\", \"they're\": \"they are\", \"they've\": \"they have\", \"to've\": \"to have\", \"wasn't\": \"was not\", \"we'd\": \"we would\", \"we'd've\": \"we would have\", \"we'll\": \"we will\", \"we'll've\": \"we will have\", \"we're\": \"we are\", \"we've\": \"we have\", \"weren't\": \"were not\", \"what'll\": \"what will\", \"what'll've\": \"what will have\", \"what're\": \"what are\",  \"what's\": \"what is\", \"what've\": \"what have\", \"when's\": \"when is\", \"when've\": \"when have\", \"where'd\": \"where did\", \"where's\": \"where is\", \"where've\": \"where have\", \"who'll\": \"who will\", \"who'll've\": \"who will have\", \"who's\": \"who is\", \"who've\": \"who have\", \"why's\": \"why is\", \"why've\": \"why have\", \"will've\": \"will have\", \"won't\": \"will not\", \"won't've\": \"will not have\", \"would've\": \"would have\", \"wouldn't\": \"would not\", \"wouldn't've\": \"would not have\", \"y'all\": \"you all\", \"y'all'd\": \"you all would\",\"y'all'd've\": \"you all would have\",\"y'all're\": \"you all are\",\"y'all've\": \"you all have\",\"you'd\": \"you would\", \"you'd've\": \"you would have\", \"you'll\": \"you will\", \"you'll've\": \"you will have\", \"you're\": \"you are\", \"you've\": \"you have\"}\n",
        "\n",
        "def _get_contractions(contraction_dict):\n",
        "    contraction_re = re.compile('(%s)' % '|'.join(contraction_dict.keys()))\n",
        "    return contraction_dict, contraction_re\n",
        "\n",
        "contractions, contractions_re = _get_contractions(contraction_dict)\n",
        "\n",
        "def replace_contractions(text):\n",
        "    def replace(match):\n",
        "        return contractions[match.group(0)]\n",
        "    return contractions_re.sub(replace, text)\n"
      ],
      "execution_count": 214,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E744km496VH5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "ix=0\n",
        "for i in X_train:\n",
        "  X_train[ix]=replace_contractions(i)\n",
        "  ix=ix+1\n",
        "ix=0\n",
        "for i in X_test:\n",
        "  X_test[ix]=replace_contractions(i)\n",
        "  ix=ix+1"
      ],
      "execution_count": 215,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ITdafg44_T7f",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Stemming\n",
        "'''Stemming is the process of converting words to their base forms using crude Heuristic rules.\n",
        "   For example, one rule could be to remove ’s’ from the end of any word, so that ‘cats’ becomes ‘cat’. \n",
        "   or another rule could be to replace ‘ies’ with ‘i’ so that ‘ponies becomes ‘poni’.'''\n",
        "from nltk.stem import  SnowballStemmer\n",
        "from nltk.tokenize.toktok import ToktokTokenizer\n",
        "def stem_text(text):\n",
        "    tokenizer = ToktokTokenizer()\n",
        "    stemmer = SnowballStemmer('english')\n",
        "    tokens = tokenizer.tokenize(text)\n",
        "    tokens = [token.strip() for token in tokens]\n",
        "    tokens = [stemmer.stem(token) for token in tokens]\n",
        "    return ' '.join(tokens)"
      ],
      "execution_count": 216,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-qppnppC_cNH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "ix=0\n",
        "for i in X_train:\n",
        "  X_train[ix]=stem_text(i)\n",
        "  ix=ix+1\n",
        "ix=0\n",
        "for i in X_test:\n",
        "  X_test[ix]=stem_text(i)\n",
        "  ix=ix+1"
      ],
      "execution_count": 217,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rhvD5-MNw9TX",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "4840e5ab-1ac7-4714-d533-858d42230a46"
      },
      "source": [
        "type(X_train)"
      ],
      "execution_count": 218,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "pandas.core.series.Series"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 218
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lrspY3inhDNr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#After removing or cleaning the text\n",
        "max_features = 11051   #No. of different words in total text 5852, 2261\n",
        "maxlen = 70           #Padding length\n",
        "embed_size = 300      #No. of dimensions of glove\n",
        "\n",
        "threshold = 0.35\n",
        "\n",
        "tokenizer = text.Tokenizer(num_words=max_features)\n",
        "tokenizer.fit_on_texts(list(X_train) + list(X_test))\n",
        "X_train = tokenizer.texts_to_sequences(X_train)\n",
        "X_test = tokenizer.texts_to_sequences(X_test)\n",
        "x_train = sequence.pad_sequences(X_train, maxlen=maxlen)\n",
        "x_test = sequence.pad_sequences(X_test, maxlen=maxlen)"
      ],
      "execution_count": 219,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OBwsgvhHhl5l",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_train = y_train.map({'HATE':0, 'OFFN': 1,'PRFN':2})    #Map accordingly \n",
        "y_test = y_test.map({'HATE':0, 'OFFN': 1,'PRFN':2})"
      ],
      "execution_count": 220,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CP4di6A42kBJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_train=keras.utils.to_categorical(y_train, num_classes=3)  #one hot encoding\n",
        "y_test=keras.utils.to_categorical(y_test, num_classes=3)\n"
      ],
      "execution_count": 221,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rsdmn7n753U4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y=[]\n",
        "for i in y_train:\n",
        " y.append(np.argmax(i))"
      ],
      "execution_count": 222,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hIwcc-NthnbT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_coefs(word, *arr): return word, np.asarray(arr, dtype='float32')\n",
        "embeddings_index = dict(get_coefs(*o.rstrip().rsplit(' ')) for o in open(EMBEDDING_FILE))\n",
        "\n",
        "word_index = tokenizer.word_index\n",
        "nb_words = min(max_features, len(word_index))\n",
        "embedding_matrix = np.zeros((nb_words, embed_size))\n",
        "for word, i in word_index.items():\n",
        "    if i >= max_features: continue\n",
        "    embedding_vector = embeddings_index.get(word)\n",
        "    if embedding_vector is not None: embedding_matrix[i] = embedding_vector"
      ],
      "execution_count": 223,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wab1NQbl92eU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "num_filters = 42\n",
        "filter_sizes = [1,2,3,5]  #ngrams"
      ],
      "execution_count": 224,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M-yKTdl7LHth",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "outputId": "57fcf6b4-dbba-434f-e4db-27ce356fd61f"
      },
      "source": [
        "#CNN\n",
        "\n",
        "def get_model():    \n",
        "    inp = Input(shape=(maxlen, ))\n",
        "    x = Embedding(max_features, embed_size, weights=[embedding_matrix])(inp)\n",
        "#    x = SpatialDropout1D(0.4)(x)\n",
        "    x = Reshape((maxlen, embed_size, 1))(x)\n",
        "    \n",
        "    conv_0 = Conv2D(num_filters, kernel_size=(filter_sizes[0], embed_size),\n",
        "                                 kernel_initializer='he_normal', activation='tanh')(x)\n",
        "    conv_1 = Conv2D(num_filters, kernel_size=(filter_sizes[1], embed_size),\n",
        "                                 kernel_initializer='he_normal', activation='tanh')(x)\n",
        "    conv_2 = Conv2D(num_filters, kernel_size=(filter_sizes[2], embed_size), \n",
        "                                 kernel_initializer='he_normal', activation='tanh')(x)\n",
        "    conv_3 = Conv2D(num_filters, kernel_size=(filter_sizes[3], embed_size),\n",
        "                                 kernel_initializer='he_normal', activation='tanh')(x)\n",
        "    \n",
        "    maxpool_0 = MaxPool2D(pool_size=(maxlen - filter_sizes[0] + 1, 1))(conv_0)\n",
        "    maxpool_1 = MaxPool2D(pool_size=(maxlen - filter_sizes[1] + 1, 1))(conv_1)\n",
        "    maxpool_2 = MaxPool2D(pool_size=(maxlen - filter_sizes[2] + 1, 1))(conv_2)\n",
        "    maxpool_3 = MaxPool2D(pool_size=(maxlen - filter_sizes[3] + 1, 1))(conv_3)\n",
        "        \n",
        "    z = Concatenate(axis=1)([maxpool_0, maxpool_1, maxpool_2, maxpool_3])   \n",
        "    z = Flatten()(z)\n",
        "    z = Dropout(0.1)(z)\n",
        "        \n",
        "    outp = Dense(3, activation=\"sigmoid\")(z)\n",
        "    \n",
        "    model = Model(inputs=inp, outputs=outp)\n",
        "    model.compile(loss='categorical_crossentropy',\n",
        "                  optimizer='adam',\n",
        "                  metrics=['accuracy'])\n",
        "\n",
        "    return model\n",
        "\n",
        "model = get_model()"
      ],
      "execution_count": 225,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4070: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K8ZcLmIb8IdF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#model of bi-lstm\n",
        "from keras.layers import Dense, Input, CuDNNLSTM, Embedding, Dropout, Activation, CuDNNGRU, Conv1D\n",
        "from keras.layers import Bidirectional, GlobalMaxPool1D, GlobalMaxPooling1D, GlobalAveragePooling1D,concatenate\n",
        "def model_lstm_atten(embedding_matrix):\n",
        "    inp = Input(shape=(maxlen,))\n",
        "    x = Embedding(max_features, embed_size, weights=[embedding_matrix])(inp)\n",
        "    '''\n",
        "    Here 64 is the size(dim) of the hidden state vector as well as the output vector. Keeping return_sequence we want the output for the entire sequence. So what is the dimension of output for this layer?\n",
        "        64*70(maxlen)*2(bidirection concat)\n",
        "    CuDNNLSTM is fast implementation of LSTM layer in Keras which only runs on GPU\n",
        "    '''\n",
        "    x = Bidirectional(CuDNNLSTM(64, return_sequences=True))(x)\n",
        "    avg_pool = GlobalAveragePooling1D()(x)\n",
        "    max_pool = GlobalMaxPooling1D()(x)\n",
        "    conc = concatenate([avg_pool, max_pool])\n",
        "    conc = Dense(64, activation=\"relu\")(conc)\n",
        "    conc = Dropout(0.1)(conc)\n",
        "    outp = Dense(3, activation=\"sigmoid\")(conc)\n",
        "    model = Model(inputs=inp, outputs=outp)\n",
        "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "    return model"
      ],
      "execution_count": 226,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uAk9X7ByvfND",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#model of lstm \n",
        "from keras.layers import Dense, Input, LSTM, Embedding, Dropout, Activation, CuDNNGRU, Conv1D\n",
        "from keras.layers import Bidirectional, GlobalMaxPool1D, GlobalMaxPooling1D, GlobalAveragePooling1D,concatenate\n",
        "def model_slstm_atten(embedding_matrix):\n",
        "    inp = Input(shape=(maxlen,))\n",
        "    x = Embedding(max_features, embed_size, weights=[embedding_matrix])(inp)\n",
        "    '''\n",
        "    Here 64 is the size(dim) of the hidden state vector as well as the output vector. Keeping return_sequence we want the output for the entire sequence. So what is the dimension of output for this layer?\n",
        "        64*70(maxlen)*2(bidirection concat)\n",
        "    LSTM is fast implementation of LSTM layer in Keras which only runs on GPU\n",
        "    '''\n",
        "    x = Bidirectional(LSTM(64, return_sequences=True))(x)\n",
        "    avg_pool = GlobalAveragePooling1D()(x)\n",
        "    max_pool = GlobalMaxPooling1D()(x)\n",
        "    conc = concatenate([avg_pool, max_pool])\n",
        "    conc = Dense(64, activation=\"relu\")(conc)\n",
        "    conc = Dropout(0.1)(conc)\n",
        "    outp = Dense(3, activation=\"sigmoid\")(conc)\n",
        "    model = Model(inputs=inp, outputs=outp)\n",
        "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "    return model"
      ],
      "execution_count": 227,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wq5rsKgyv080",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#model of gru \n",
        "from keras.layers import Dense, Input, GRU, Embedding, Dropout, Activation, CuDNNGRU, Conv1D\n",
        "from keras.layers import Bidirectional, GlobalMaxPool1D, GlobalMaxPooling1D, GlobalAveragePooling1D,concatenate\n",
        "def model_gru_atten(embedding_matrix):\n",
        "    inp = Input(shape=(maxlen,))\n",
        "    x = Embedding(max_features, embed_size, weights=[embedding_matrix])(inp)\n",
        "    '''\n",
        "    Here 64 is the size(dim) of the hidden state vector as well as the output vector. Keeping return_sequence we want the output for the entire sequence. So what is the dimension of output for this layer?\n",
        "        64*70(maxlen)*2(bidirection concat)\n",
        "    GRU is fast implementation of LSTM layer in Keras which only runs on GPU\n",
        "    '''\n",
        "    x = Bidirectional(GRU(64, return_sequences=True))(x)\n",
        "    avg_pool = GlobalAveragePooling1D()(x)\n",
        "    max_pool = GlobalMaxPooling1D()(x)\n",
        "    conc = concatenate([avg_pool, max_pool])\n",
        "    conc = Dense(64, activation=\"relu\")(conc)\n",
        "    conc = Dropout(0.1)(conc)\n",
        "    outp = Dense(3, activation=\"sigmoid\")(conc)\n",
        "    model = Model(inputs=inp, outputs=outp)\n",
        "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "    return model"
      ],
      "execution_count": 228,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ShKIosLhwO-J",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#model of Simple RNN \n",
        "from keras.layers import Dense, Input, SimpleRNN, Embedding, Dropout, Activation, CuDNNGRU, Conv1D\n",
        "from keras.layers import Bidirectional, GlobalMaxPool1D, GlobalMaxPooling1D, GlobalAveragePooling1D,concatenate\n",
        "def model_rnn_atten(embedding_matrix):\n",
        "    inp = Input(shape=(maxlen,))\n",
        "    x = Embedding(max_features, embed_size, weights=[embedding_matrix])(inp)\n",
        "    '''\n",
        "    Here 64 is the size(dim) of the hidden state vector as well as the output vector. Keeping return_sequence we want the output for the entire sequence. So what is the dimension of output for this layer?\n",
        "        64*70(maxlen)*2(bidirection concat)\n",
        "    SimpleRNN is fast implementation of LSTM layer in Keras which only runs on GPU\n",
        "    '''\n",
        "    x = Bidirectional(SimpleRNN(64, return_sequences=True))(x)\n",
        "    avg_pool = GlobalAveragePooling1D()(x)\n",
        "    max_pool = GlobalMaxPooling1D()(x)\n",
        "    conc = concatenate([avg_pool, max_pool])\n",
        "    conc = Dense(64, activation=\"relu\")(conc)\n",
        "    conc = Dropout(0.1)(conc)\n",
        "    outp = Dense(3, activation=\"sigmoid\")(conc)\n",
        "    model = Model(inputs=inp, outputs=outp)\n",
        "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "    return model"
      ],
      "execution_count": 229,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TbTCbl1ELheN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 370
        },
        "outputId": "92e5bca1-eb0b-40b5-c6cf-7cd09e6ab609"
      },
      "source": [
        "hist = model.fit(X_tra, y_tra, batch_size=batch_size, epochs=epochs,\n",
        "                 validation_data=(X_val, y_val),\n",
        "                  verbose=2)"
      ],
      "execution_count": 230,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 2147 samples, validate on 114 samples\n",
            "Epoch 1/10\n",
            " - 3s - loss: 1.0525 - accuracy: 0.4420 - val_loss: 0.9786 - val_accuracy: 0.5263\n",
            "Epoch 2/10\n",
            " - 0s - loss: 0.9384 - accuracy: 0.5137 - val_loss: 0.9560 - val_accuracy: 0.5439\n",
            "Epoch 3/10\n",
            " - 0s - loss: 0.8583 - accuracy: 0.5449 - val_loss: 0.9467 - val_accuracy: 0.5614\n",
            "Epoch 4/10\n",
            " - 0s - loss: 0.7646 - accuracy: 0.6143 - val_loss: 0.9327 - val_accuracy: 0.5439\n",
            "Epoch 5/10\n",
            " - 0s - loss: 0.6508 - accuracy: 0.7788 - val_loss: 0.9243 - val_accuracy: 0.5614\n",
            "Epoch 6/10\n",
            " - 0s - loss: 0.5433 - accuracy: 0.8011 - val_loss: 0.9281 - val_accuracy: 0.5614\n",
            "Epoch 7/10\n",
            " - 0s - loss: 0.4373 - accuracy: 0.9073 - val_loss: 0.9163 - val_accuracy: 0.5965\n",
            "Epoch 8/10\n",
            " - 0s - loss: 0.3631 - accuracy: 0.9287 - val_loss: 0.9011 - val_accuracy: 0.6053\n",
            "Epoch 9/10\n",
            " - 0s - loss: 0.2900 - accuracy: 0.9595 - val_loss: 0.9157 - val_accuracy: 0.6140\n",
            "Epoch 10/10\n",
            " - 0s - loss: 0.2297 - accuracy: 0.9776 - val_loss: 0.9071 - val_accuracy: 0.6140\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "os7L-_L-1E9C",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "e540088b-4a8a-4475-bddc-62a70a942737"
      },
      "source": [
        "print(tf.__version__)"
      ],
      "execution_count": 231,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1.15.2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f3IknJPBKhNm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 231,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OjdZQ6CivX6A",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "ls_model = model_lstm_atten(embedding_matrix) #model of bi-lstm with attention"
      ],
      "execution_count": 232,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i2mQmYBpv9pe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sls_model = model_slstm_atten(embedding_matrix) #model of lstm with attention"
      ],
      "execution_count": 233,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QS775wFCwC7f",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "gru_model = model_gru_atten(embedding_matrix) #model of gru with attention"
      ],
      "execution_count": 234,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RpGGm6aLwXAO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "rnn_model = model_rnn_atten(embedding_matrix) #model of rnn with attention"
      ],
      "execution_count": 235,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s8J_qWpbdihB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "batch_size = 256\n",
        "epochs = 10\n",
        "\n",
        "X_tra, X_val, y_tra, y_val = train_test_split(x_train, y_train, train_size=0.95,\n",
        "                                              random_state=42) #split this into train and validation"
      ],
      "execution_count": 236,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aomeeixP8jb5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 370
        },
        "outputId": "298327e6-42ed-462b-df28-e82c374149a9"
      },
      "source": [
        "ls_hist = ls_model.fit(X_tra, y_tra, batch_size=batch_size, epochs=epochs,\n",
        "                 validation_data=(X_val, y_val),\n",
        "                  verbose=2)      #Train bi-lstm with attention"
      ],
      "execution_count": 237,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 2147 samples, validate on 114 samples\n",
            "Epoch 1/10\n",
            " - 3s - loss: 1.0574 - accuracy: 0.4690 - val_loss: 0.9885 - val_accuracy: 0.5263\n",
            "Epoch 2/10\n",
            " - 0s - loss: 1.0068 - accuracy: 0.5044 - val_loss: 0.9743 - val_accuracy: 0.5263\n",
            "Epoch 3/10\n",
            " - 0s - loss: 0.9544 - accuracy: 0.5207 - val_loss: 0.9541 - val_accuracy: 0.5702\n",
            "Epoch 4/10\n",
            " - 0s - loss: 0.8736 - accuracy: 0.5855 - val_loss: 0.9586 - val_accuracy: 0.5877\n",
            "Epoch 5/10\n",
            " - 0s - loss: 0.7681 - accuracy: 0.6577 - val_loss: 0.9471 - val_accuracy: 0.6053\n",
            "Epoch 6/10\n",
            " - 0s - loss: 0.6364 - accuracy: 0.7098 - val_loss: 0.9513 - val_accuracy: 0.6140\n",
            "Epoch 7/10\n",
            " - 0s - loss: 0.5376 - accuracy: 0.7611 - val_loss: 1.0260 - val_accuracy: 0.6316\n",
            "Epoch 8/10\n",
            " - 0s - loss: 0.4311 - accuracy: 0.8179 - val_loss: 1.1046 - val_accuracy: 0.5877\n",
            "Epoch 9/10\n",
            " - 0s - loss: 0.3388 - accuracy: 0.8659 - val_loss: 1.2345 - val_accuracy: 0.5702\n",
            "Epoch 10/10\n",
            " - 0s - loss: 0.2604 - accuracy: 0.9101 - val_loss: 1.2897 - val_accuracy: 0.5439\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ogHvVYE9wqfj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 370
        },
        "outputId": "c3f83751-bad6-46ff-8067-19830abafa96"
      },
      "source": [
        "sls_hist = sls_model.fit(X_tra, y_tra, batch_size=batch_size, epochs=epochs,\n",
        "                 validation_data=(X_val, y_val),\n",
        "                  verbose=2)    #Train lstm with attention"
      ],
      "execution_count": 238,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 2147 samples, validate on 114 samples\n",
            "Epoch 1/10\n",
            " - 4s - loss: 1.0512 - accuracy: 0.4835 - val_loss: 0.9854 - val_accuracy: 0.5263\n",
            "Epoch 2/10\n",
            " - 2s - loss: 0.9938 - accuracy: 0.5044 - val_loss: 0.9817 - val_accuracy: 0.5263\n",
            "Epoch 3/10\n",
            " - 2s - loss: 0.9441 - accuracy: 0.5254 - val_loss: 0.9536 - val_accuracy: 0.5877\n",
            "Epoch 4/10\n",
            " - 2s - loss: 0.8647 - accuracy: 0.6102 - val_loss: 0.9844 - val_accuracy: 0.5614\n",
            "Epoch 5/10\n",
            " - 2s - loss: 0.7420 - accuracy: 0.6796 - val_loss: 0.9319 - val_accuracy: 0.6053\n",
            "Epoch 6/10\n",
            " - 2s - loss: 0.6009 - accuracy: 0.7424 - val_loss: 1.0238 - val_accuracy: 0.6228\n",
            "Epoch 7/10\n",
            " - 2s - loss: 0.5196 - accuracy: 0.7951 - val_loss: 1.0079 - val_accuracy: 0.6316\n",
            "Epoch 8/10\n",
            " - 2s - loss: 0.4162 - accuracy: 0.8356 - val_loss: 1.0201 - val_accuracy: 0.6491\n",
            "Epoch 9/10\n",
            " - 2s - loss: 0.3178 - accuracy: 0.8817 - val_loss: 1.1666 - val_accuracy: 0.5789\n",
            "Epoch 10/10\n",
            " - 2s - loss: 0.2298 - accuracy: 0.9264 - val_loss: 1.4004 - val_accuracy: 0.5351\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a0vakaVYw0FM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 370
        },
        "outputId": "f9d79a30-1977-451e-d22e-427fb30caeda"
      },
      "source": [
        "gru_hist = gru_model.fit(X_tra, y_tra, batch_size=batch_size, epochs=epochs,\n",
        "                 validation_data=(X_val, y_val),\n",
        "                  verbose=2)      #Train GRU with attention"
      ],
      "execution_count": 239,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 2147 samples, validate on 114 samples\n",
            "Epoch 1/10\n",
            " - 5s - loss: 1.0692 - accuracy: 0.4457 - val_loss: 1.0016 - val_accuracy: 0.5175\n",
            "Epoch 2/10\n",
            " - 2s - loss: 1.0061 - accuracy: 0.5068 - val_loss: 0.9768 - val_accuracy: 0.5175\n",
            "Epoch 3/10\n",
            " - 2s - loss: 0.9626 - accuracy: 0.5217 - val_loss: 0.9575 - val_accuracy: 0.5702\n",
            "Epoch 4/10\n",
            " - 2s - loss: 0.8992 - accuracy: 0.5762 - val_loss: 0.9310 - val_accuracy: 0.5702\n",
            "Epoch 5/10\n",
            " - 2s - loss: 0.8053 - accuracy: 0.6418 - val_loss: 0.9071 - val_accuracy: 0.5877\n",
            "Epoch 6/10\n",
            " - 2s - loss: 0.6994 - accuracy: 0.6917 - val_loss: 0.8784 - val_accuracy: 0.6053\n",
            "Epoch 7/10\n",
            " - 2s - loss: 0.5926 - accuracy: 0.7308 - val_loss: 0.9314 - val_accuracy: 0.6316\n",
            "Epoch 8/10\n",
            " - 2s - loss: 0.4931 - accuracy: 0.7713 - val_loss: 0.9479 - val_accuracy: 0.6053\n",
            "Epoch 9/10\n",
            " - 2s - loss: 0.4038 - accuracy: 0.8235 - val_loss: 0.9980 - val_accuracy: 0.6491\n",
            "Epoch 10/10\n",
            " - 2s - loss: 0.3221 - accuracy: 0.8635 - val_loss: 1.1786 - val_accuracy: 0.6140\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K_vYITbcw6op",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 370
        },
        "outputId": "53d4d1fd-91d2-4cb6-cd3c-96f2aaccd4a1"
      },
      "source": [
        "rnn_hist = rnn_model.fit(X_tra, y_tra, batch_size=batch_size, epochs=epochs,\n",
        "                 validation_data=(X_val, y_val),\n",
        "                  verbose=2)      #Train RNN with attention"
      ],
      "execution_count": 240,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 2147 samples, validate on 114 samples\n",
            "Epoch 1/10\n",
            " - 3s - loss: 1.0450 - accuracy: 0.4793 - val_loss: 0.9855 - val_accuracy: 0.5263\n",
            "Epoch 2/10\n",
            " - 1s - loss: 1.0004 - accuracy: 0.5054 - val_loss: 0.9738 - val_accuracy: 0.5263\n",
            "Epoch 3/10\n",
            " - 1s - loss: 0.9625 - accuracy: 0.5086 - val_loss: 0.9590 - val_accuracy: 0.5175\n",
            "Epoch 4/10\n",
            " - 1s - loss: 0.9085 - accuracy: 0.5319 - val_loss: 0.9586 - val_accuracy: 0.5175\n",
            "Epoch 5/10\n",
            " - 1s - loss: 0.8093 - accuracy: 0.6339 - val_loss: 0.9463 - val_accuracy: 0.4649\n",
            "Epoch 6/10\n",
            " - 1s - loss: 0.7078 - accuracy: 0.7205 - val_loss: 0.9537 - val_accuracy: 0.5526\n",
            "Epoch 7/10\n",
            " - 1s - loss: 0.5674 - accuracy: 0.7844 - val_loss: 1.0625 - val_accuracy: 0.4561\n",
            "Epoch 8/10\n",
            " - 1s - loss: 0.4613 - accuracy: 0.8491 - val_loss: 1.0502 - val_accuracy: 0.5351\n",
            "Epoch 9/10\n",
            " - 1s - loss: 0.3526 - accuracy: 0.8919 - val_loss: 0.9856 - val_accuracy: 0.5351\n",
            "Epoch 10/10\n",
            " - 1s - loss: 0.2684 - accuracy: 0.9255 - val_loss: 1.0727 - val_accuracy: 0.4912\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6gKkthjNz8-g",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.metrics import classification_report"
      ],
      "execution_count": 241,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3pSzYa3_y4dw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_t=[]\n",
        "for i in y_test:\n",
        "  y_t.append(np.argmax(i))    #Using argmax to find the index of one hot encoding"
      ],
      "execution_count": 242,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MgYpjoGMMKAP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y__pred =model.predict(x_test)      #predict y_test by bi-lstm with attention\n",
        "y__p=[]\n",
        "for i in y__pred:\n",
        "  y__p.append(np.argmax(i))"
      ],
      "execution_count": 243,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j-tcOAWtMMFw",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 218
        },
        "outputId": "105175f2-1780-427e-de1a-3fa9ded3d2dc"
      },
      "source": [
        "print('Model = CNN\\n')  \n",
        "print(classification_report(y_t, y__p))"
      ],
      "execution_count": 244,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model = CNN\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.61      0.90      0.72       124\n",
            "           1       0.67      0.06      0.10        71\n",
            "           2       0.74      0.77      0.76        93\n",
            "\n",
            "    accuracy                           0.65       288\n",
            "   macro avg       0.67      0.58      0.53       288\n",
            "weighted avg       0.66      0.65      0.58       288\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uWGsz9rSzxrb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_ls_pred = ls_model.predict(x_test)      #predict y_test by bi-lstm with attention\n",
        "y_ls_p=[]\n",
        "for i in y_ls_pred:\n",
        "  y_ls_p.append(np.argmax(i))\n"
      ],
      "execution_count": 245,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PHMWJ9719I26",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 218
        },
        "outputId": "d58ebd5f-2917-46e1-9310-040dab37ae30"
      },
      "source": [
        "print('Model = Attention Bidirectonal LSTM\\n')  \n",
        "print(classification_report(y_t, y_ls_p))"
      ],
      "execution_count": 246,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model = Attention Bidirectonal LSTM\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.62      0.78      0.69       124\n",
            "           1       0.48      0.14      0.22        71\n",
            "           2       0.65      0.77      0.71        93\n",
            "\n",
            "    accuracy                           0.62       288\n",
            "   macro avg       0.58      0.57      0.54       288\n",
            "weighted avg       0.59      0.62      0.58       288\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PFFok56rxDAd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_sls_pred = sls_model.predict(x_test)  #predict y_test by lstm with attention\n",
        "y_sls_p=[]\n",
        "for i in y_sls_pred:\n",
        "  y_sls_p.append(np.argmax(i))"
      ],
      "execution_count": 247,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wcFHJ7TExGua",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 218
        },
        "outputId": "b92af59e-e6ae-4843-85eb-2b4f308f4f94"
      },
      "source": [
        "print('Model = Attention LSTM\\n')\n",
        "print(classification_report(y_t, y_sls_p))"
      ],
      "execution_count": 248,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model = Attention LSTM\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.67      0.56      0.61       124\n",
            "           1       0.36      0.38      0.37        71\n",
            "           2       0.67      0.80      0.73        93\n",
            "\n",
            "    accuracy                           0.59       288\n",
            "   macro avg       0.57      0.58      0.57       288\n",
            "weighted avg       0.59      0.59      0.59       288\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "R4K_8-gvxQSb",
        "colab": {}
      },
      "source": [
        "y_gru_pred = gru_model.predict(x_test)    #predict y_test by GRU with attention\n",
        "y_gru_p=[]\n",
        "for i in y_gru_pred:\n",
        "  y_gru_p.append(np.argmax(i))"
      ],
      "execution_count": 249,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Va13oAXAxQSd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 218
        },
        "outputId": "4d4dc2f0-e89c-419f-c38e-c9ef66d0f00c"
      },
      "source": [
        "print('Model = Attention GRU\\n')\n",
        "print(classification_report(y_t, y_gru_p))"
      ],
      "execution_count": 250,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model = Attention GRU\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.69      0.87      0.77       124\n",
            "           1       1.00      0.06      0.11        71\n",
            "           2       0.62      0.85      0.71        93\n",
            "\n",
            "    accuracy                           0.66       288\n",
            "   macro avg       0.77      0.59      0.53       288\n",
            "weighted avg       0.74      0.66      0.59       288\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "DJIkpqBHxbbr",
        "colab": {}
      },
      "source": [
        "y_rnn_pred = rnn_model.predict(x_test)    #predict y_test by RNN with attention\n",
        "y_rnn_p=[]\n",
        "for i in y_rnn_pred:\n",
        "  y_rnn_p.append(np.argmax(i))"
      ],
      "execution_count": 251,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "FrDWDDMXxbbv",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 218
        },
        "outputId": "705de584-d50d-486d-cf3c-cc6e844b8981"
      },
      "source": [
        "print('Model = Attention SimpleRNN\\n')\n",
        "print(classification_report(y_t, y_rnn_p))"
      ],
      "execution_count": 252,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model = Attention SimpleRNN\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.53      0.69      0.60       124\n",
            "           1       0.30      0.20      0.24        71\n",
            "           2       0.64      0.57      0.60        93\n",
            "\n",
            "    accuracy                           0.53       288\n",
            "   macro avg       0.49      0.48      0.48       288\n",
            "weighted avg       0.51      0.53      0.51       288\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}